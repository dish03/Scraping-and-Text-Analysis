{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd13ea28",
   "metadata": {},
   "source": [
    "### Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eac057bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import pprint\n",
    "import os\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "import zipfile\n",
    "import syllables\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11edc465",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\disha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\disha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea81b97c",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d679cf04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>321.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-e-hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2345.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-e-hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4321.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>432.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL\n",
       "0   123.0  https://insights.blackcoffer.com/rise-of-telem...\n",
       "1   321.0  https://insights.blackcoffer.com/rise-of-e-hea...\n",
       "2  2345.0  https://insights.blackcoffer.com/rise-of-e-hea...\n",
       "3  4321.0  https://insights.blackcoffer.com/rise-of-telem...\n",
       "4   432.0  https://insights.blackcoffer.com/rise-of-telem..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\disha\\Downloads\\Input.xlsx - Sheet1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f74a0d3",
   "metadata": {},
   "source": [
    "### Function to scrape the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34f7c200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_url(url, output_file):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, 'html5lib')\n",
    "    # print(soup.prettify())\n",
    "    title = soup.find_all('h1', attrs={'class': \"entry-title\"})\n",
    "    if title:\n",
    "        title_text = title[0].get_text()\n",
    "    else:\n",
    "        title_text = \"Not Found\"\n",
    "#     print(title_text)\n",
    "    \n",
    "    content = soup.find_all('div', attrs={'class': 'td-post-content tagdiv-type'})\n",
    "\n",
    "    if content:\n",
    "        text = \"\"\n",
    "        for paragraph in content[0].find_all('p'):\n",
    "            text += paragraph.get_text() + \"\\n\"\n",
    "#         print(text)\n",
    "    else:\n",
    "        text = \"Content not found\"\n",
    "\n",
    "        \n",
    "#     Append the title and text to the output file\n",
    "    with open(output_file, 'a', encoding='utf-8') as file:\n",
    "        file.write(f\"Title: {title_text}\\n\")\n",
    "        file.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64382e01",
   "metadata": {},
   "source": [
    "### Creating output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22967d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = \"output_text_files/\"  # Creating an output directory\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "for index, row in df.iterrows():\n",
    "    url_id = row['URL_ID']\n",
    "    url = row['URL']\n",
    "    output_file = os.path.join(output_directory, f\"{url_id}.txt\")  # Create the output file path\n",
    "\n",
    "    scrape_url(url, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca50544",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81eff02",
   "metadata": {},
   "source": [
    "#### Storing stop words as a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13806cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_zip = r\"C:\\Users\\disha\\Downloads\\StopWords-20230919T180021Z-001.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86bb928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract stop words from the ZIP file\n",
    "stop_words = set()\n",
    "\n",
    "with zipfile.ZipFile(stop_words_zip, 'r') as zip_file:\n",
    "    for file_name in zip_file.namelist():\n",
    "        with zip_file.open(file_name) as word_file:\n",
    "            word_list = [line.decode('latin-1').strip().lower() for line in word_file]\n",
    "            stop_words.update(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc68d7d",
   "metadata": {},
   "source": [
    "#### Reading positive and negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aef4e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words_file = r\"C:\\Users\\disha\\Downloads\\positive-words.txt\"\n",
    "with open(positive_words_file, 'r', encoding='utf-8') as pos_file:\n",
    "    positive_words = set([line.strip() for line in pos_file])\n",
    "    \n",
    "negative_words_file = r\"C:\\Users\\disha\\OneDrive\\Documents\\negative-words.txt\"\n",
    "with open(negative_words_file, 'r', encoding='utf-8') as neg_file:\n",
    "    negative_words = set([line.strip() for line in neg_file])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074a4f7c",
   "metadata": {},
   "source": [
    "### 1. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758fa644",
   "metadata": {},
   "source": [
    "#### Function to clean using stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c2b2f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove stop words from a text\n",
    "def remove_stopwords(text):\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words and word not in string.punctuation]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540ddae8",
   "metadata": {},
   "source": [
    "#### Function to calculate positive score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f01d6885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the positive score using the positive word dictionary\n",
    "def calculate_positive_score(text, positive_words):\n",
    "    words = text.split()\n",
    "    positive_score = sum(1 if word.lower() in positive_words else 0 for word in words)\n",
    "    return positive_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c475e24",
   "metadata": {},
   "source": [
    "#### Function to calculate negative score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73ebc542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the negative score using the negative word dictionary\n",
    "def calculate_negative_score(text, negative_words):\n",
    "    words = text.split()\n",
    "    negative_score = sum(-1 if word.lower() in negative_words else 0 for word in words)\n",
    "    return negative_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b5d306",
   "metadata": {},
   "source": [
    "#### Function to calculate polarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7fb8769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the polarity score\n",
    "def calculate_polarity_score(positive_score, negative_score):\n",
    "    polarity_score = (positive_score - negative_score) / ((positive_score + negative_score) + 0.000001)\n",
    "    return polarity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e90bf20",
   "metadata": {},
   "source": [
    "#### Function to calculate subjectivity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d9f6a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the subjectivity score\n",
    "def calculate_subjectivity_score(positive_score, negative_score, total_words):\n",
    "    subjectivity_score = (positive_score + negative_score) / (total_words + 0.000001)\n",
    "    return subjectivity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e0a612",
   "metadata": {},
   "source": [
    "### 2. Analysis of readibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97712859",
   "metadata": {},
   "source": [
    "#### Function to calculate complex wrod count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa913ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the count of complex words\n",
    "def calculate_complex_word_count(text):\n",
    "    words = text.split()\n",
    "    complex_word_count = sum(1 for word in words if syllables.estimate(word) > 2)\n",
    "    return complex_word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31776233",
   "metadata": {},
   "source": [
    "#### Function to count the number of syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7e3c469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_syllables(word):\n",
    "    # Convert the word to lowercase for consistent counting\n",
    "    word = word.lower()\n",
    "    \n",
    "    # Remove common suffixes that do not contribute to syllable count\n",
    "    exceptions = [\"es\", \"ed\"]\n",
    "    for exception in exceptions:\n",
    "        if word.endswith(exception):\n",
    "            word = word[:-len(exception)]\n",
    "    \n",
    "    # Count the number of vowels (a, e, i, o, u) in the word\n",
    "    vowels = \"aeiou\"\n",
    "    syllable_count = sum(1 for letter in word if letter in vowels)\n",
    "    \n",
    "    # Handle words with no vowels\n",
    "    if syllable_count == 0:\n",
    "        syllable_count = 1\n",
    "    \n",
    "    return syllable_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54561fb3",
   "metadata": {},
   "source": [
    "#### Function to count personal pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d325f078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_personal_pronouns(text):\n",
    "    # Define the regular expression pattern for personal pronouns\n",
    "    pronoun_pattern = r'\\b(?:[Ii]|we|my|ours|us)\\b'\n",
    "    \n",
    "    # Use the regex pattern to find and count personal pronouns in the text\n",
    "    personal_pronoun_matches = re.findall(pronoun_pattern, text)\n",
    "    \n",
    "    # Exclude instances where \"US\" refers to the country name\n",
    "    filtered_pronouns = [pronoun for pronoun in personal_pronoun_matches if pronoun.lower() != 'us']\n",
    "    \n",
    "    return len(filtered_pronouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcb6a42",
   "metadata": {},
   "source": [
    "#### Function to calculate average word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "062629af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the average word length\n",
    "def calculate_average_word_length(text):\n",
    "    words = word_tokenize(text)\n",
    "    total_characters = sum(len(word) for word in words)\n",
    "    total_words = len(words)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if total_words > 0:\n",
    "        avg_word_length = total_characters / total_words\n",
    "    else:\n",
    "        avg_word_length = 0\n",
    "    \n",
    "    return avg_word_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17df2c42",
   "metadata": {},
   "source": [
    "#### Function to analyze the entire text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29561218",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define a function to analyze a text file and calculate the specified factors\n",
    "def analyze_text_file(file_path,sia):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "        # Remove stop words\n",
    "        cleaned_text = remove_stopwords(text)\n",
    "\n",
    "        # Calculate sentiment scores\n",
    "        sentiment_scores = sia.polarity_scores(cleaned_text)\n",
    "        positive_score = calculate_positive_score(cleaned_text,positive_words)\n",
    "        negative_score = calculate_negative_score(cleaned_text,negative_words)\n",
    "        \n",
    "        polarity_score = calculate_polarity_score(positive_score, negative_score)\n",
    "        \n",
    "        # Tokenize the cleaned text into sentences and words\n",
    "        sentences = sent_tokenize(cleaned_text)\n",
    "        words = word_tokenize(cleaned_text)\n",
    "        \n",
    "        subjectivity_score = calculate_subjectivity_score(positive_score, negative_score, len(words))\n",
    "        \n",
    "        # Calculate Average Sentence Length\n",
    "        avg_sentence_length = len(words) / len(sentences) if len(sentences) > 0 else 0\n",
    "        \n",
    "        #Calculate complex word count\n",
    "        complex_word_count = calculate_complex_word_count(cleaned_text)\n",
    "        \n",
    "        # Calculate Percentage of Complex Words\n",
    "        percentage_complex_words = complex_word_count / len(words) if len(words) > 0 else 0\n",
    "        \n",
    "        # Calculate Fog Index\n",
    "        fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)\n",
    "        \n",
    "        # Calculate Average Number of Words Per Sentence\n",
    "        avg_words_per_sentence = len(words) / len(sentences) if len(sentences) > 0 else 0\n",
    "        \n",
    "        #Calculate the word count\n",
    "        word_count = len(words)\n",
    "        \n",
    "        # Calculate Syllables Per Word\n",
    "        syllables_per_word = sum(count_syllables(word) for word in words) / len(words) if len(words) > 0 else 0\n",
    "        \n",
    "        # Calculate Personal Pronoun Count\n",
    "        personal_pronoun_count = count_personal_pronouns(cleaned_text)\n",
    "        \n",
    "        # Calculate Average Word Length\n",
    "        average_word_length = calculate_average_word_length(cleaned_text)\n",
    "        \n",
    "        factors = {\n",
    "            'POSITIVE SCORE': positive_score,\n",
    "            'NEGATIVE SCORE': negative_score,\n",
    "            'POLARITY SCORE': polarity_score,\n",
    "            'SUBJECTIVITY SCORE': subjectivity_score,\n",
    "            'AVG SENTENCE LENGTH': avg_sentence_length,\n",
    "            'PERCENTAGE OF COMPLEX WORDS': percentage_complex_words,\n",
    "            'FOG INDEX': fog_index,\n",
    "            'AVG NUMBER OF WORDS PER SENTENCE': avg_words_per_sentence,\n",
    "            'COMPLEX WORD COUNT': complex_word_count,\n",
    "            'WORD COUNT': word_count,\n",
    "            'SYLLABLES PER WORD': syllables_per_word,\n",
    "            'PERSONAL PRONOUNS': personal_pronoun_count,\n",
    "            'AVERAGE WORD LENGTH': average_word_length  \n",
    "        }\n",
    "        \n",
    "        return factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d96cbed",
   "metadata": {},
   "source": [
    "### Generating the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfc389cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLES PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVERAGE WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10282.6</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>55</td>\n",
       "      <td>-23</td>\n",
       "      <td>2.4375</td>\n",
       "      <td>0.040712</td>\n",
       "      <td>112.285714</td>\n",
       "      <td>0.438931</td>\n",
       "      <td>45.089858</td>\n",
       "      <td>112.285714</td>\n",
       "      <td>345</td>\n",
       "      <td>786</td>\n",
       "      <td>2.530534</td>\n",
       "      <td>0</td>\n",
       "      <td>6.969466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10744.4</td>\n",
       "      <td>https://insights.blackcoffer.com/man-and-machi...</td>\n",
       "      <td>42</td>\n",
       "      <td>-22</td>\n",
       "      <td>3.2000</td>\n",
       "      <td>0.036630</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>72.971429</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>234</td>\n",
       "      <td>546</td>\n",
       "      <td>2.521978</td>\n",
       "      <td>0</td>\n",
       "      <td>6.963370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11206.2</td>\n",
       "      <td>https://insights.blackcoffer.com/in-future-or-...</td>\n",
       "      <td>22</td>\n",
       "      <td>-11</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>0.033233</td>\n",
       "      <td>165.500000</td>\n",
       "      <td>0.486405</td>\n",
       "      <td>66.394562</td>\n",
       "      <td>165.500000</td>\n",
       "      <td>161</td>\n",
       "      <td>331</td>\n",
       "      <td>2.501511</td>\n",
       "      <td>0</td>\n",
       "      <td>7.078550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11668.0</td>\n",
       "      <td>https://insights.blackcoffer.com/how-neural-ne...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12129.8</td>\n",
       "      <td>https://insights.blackcoffer.com/how-machine-l...</td>\n",
       "      <td>33</td>\n",
       "      <td>-13</td>\n",
       "      <td>2.3000</td>\n",
       "      <td>0.062893</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>0.389937</td>\n",
       "      <td>63.755975</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>124</td>\n",
       "      <td>318</td>\n",
       "      <td>2.361635</td>\n",
       "      <td>0</td>\n",
       "      <td>6.588050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0  10282.6  https://insights.blackcoffer.com/will-ai-repla...              55   \n",
       "1  10744.4  https://insights.blackcoffer.com/man-and-machi...              42   \n",
       "2  11206.2  https://insights.blackcoffer.com/in-future-or-...              22   \n",
       "3  11668.0  https://insights.blackcoffer.com/how-neural-ne...               0   \n",
       "4  12129.8  https://insights.blackcoffer.com/how-machine-l...              33   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  \\\n",
       "0             -23          2.4375            0.040712           112.285714   \n",
       "1             -22          3.2000            0.036630           182.000000   \n",
       "2             -11          3.0000            0.033233           165.500000   \n",
       "3               0          0.0000            0.000000             5.000000   \n",
       "4             -13          2.3000            0.062893           159.000000   \n",
       "\n",
       "   PERCENTAGE OF COMPLEX WORDS  FOG INDEX  AVG NUMBER OF WORDS PER SENTENCE  \\\n",
       "0                     0.438931  45.089858                        112.285714   \n",
       "1                     0.428571  72.971429                        182.000000   \n",
       "2                     0.486405  66.394562                        165.500000   \n",
       "3                     0.000000   2.000000                          5.000000   \n",
       "4                     0.389937  63.755975                        159.000000   \n",
       "\n",
       "   COMPLEX WORD COUNT  WORD COUNT  SYLLABLES PER WORD  PERSONAL PRONOUNS  \\\n",
       "0                 345         786            2.530534                  0   \n",
       "1                 234         546            2.521978                  0   \n",
       "2                 161         331            2.501511                  0   \n",
       "3                   0           5            2.000000                  0   \n",
       "4                 124         318            2.361635                  0   \n",
       "\n",
       "   AVERAGE WORD LENGTH  \n",
       "0             6.969466  \n",
       "1             6.963370  \n",
       "2             7.078550  \n",
       "3             5.400000  \n",
       "4             6.588050  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the directory containing the text files\n",
    "text_files_directory = \"output_text_files/\"\n",
    "\n",
    "# Initialize a list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate through text files and analyze each one\n",
    "for filename in os.listdir(text_files_directory):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(text_files_directory, filename)\n",
    "        url_id = filename.split('.txt')[0]\n",
    "#         print(url_id)\n",
    "\n",
    "        # Find the URL associated with the URL_ID by iterating through the DataFrame\n",
    "        url = None\n",
    "        for index, row in df.iterrows():\n",
    "            if row['URL_ID'] == float(url_id):\n",
    "                url = row['URL']\n",
    "                break  # Found the URL, so exit the loop\n",
    "#         print(url)\n",
    "\n",
    "#         Create a dictionary with the URL_ID, URL, and factors\n",
    "        if url is not None:\n",
    "            factors = analyze_text_file(file_path, sia)\n",
    "            row_data = {'URL_ID': url_id, 'URL': url, **factors}\n",
    "            data.append(row_data)\n",
    "\n",
    "# Create a DataFrame from the list of data\n",
    "output = pd.DataFrame(data)\n",
    "output.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb16359",
   "metadata": {},
   "source": [
    "#### Converting into excel format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "762da13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output Excel file path\n",
    "output_excel_file = \"output_analysis.xlsx\"\n",
    "# Save the DataFrame to an Excel file\n",
    "output.to_excel(output_excel_file, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126445c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
